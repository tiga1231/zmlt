{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from time import time\n",
    "import re\n",
    "import json\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import math\n",
    "from random import random, shuffle, choice\n",
    "\n",
    "# import pydot\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx.drawing.nx_pydot import read_dot\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "from matplotlib import collections  as mc\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-colorblind')\n",
    "from IPython.display import clear_output\n",
    "\n",
    "nodePattern = re.compile('^(\\d+) ')\n",
    "edgePattern = re.compile('^(\\d+) -- (\\d+)')\n",
    "attrsPattern = re.compile('\\[(.+)\\]')\n",
    "\n",
    "def isNode(line):\n",
    "    return '--' not in line\n",
    "\n",
    "\n",
    "def processAttrs(line):\n",
    "    attrs = attrsPattern.findall(line)\n",
    "    if len(attrs) > 0:\n",
    "        attrs = attrs[0].split(',')\n",
    "    attrs = [a.split('=') for a in attrs]\n",
    "    attrs = [[a[0].strip(), a[1].replace('\"','').strip()] for a in attrs]\n",
    "    for a in attrs:\n",
    "        try:\n",
    "            a[1] = int(a[1])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                a[1] = float(a[1])\n",
    "            except:\n",
    "                pass\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def processEdge(line):\n",
    "    finding = edgePattern.findall(line)[0]\n",
    "    source, target = finding[:2]\n",
    "    source, target = int(source), int(target)\n",
    "    attrs = processAttrs(line)\n",
    "    return dict(attrs, source=source, target=target)\n",
    "\n",
    "\n",
    "def processNode(line):\n",
    "    nodeId = int(line.split(' ')[0])\n",
    "    nodeAttrs = processAttrs(line)\n",
    "    return dict(nodeAttrs, id=nodeId)\n",
    "\n",
    "\n",
    "def draw(g, pos, edges=True, labels=False, figsize=[8,8], s=2, lw=0.5):\n",
    "    xy = np.array(list([pos[k] for k in g.nodes]))\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "    ## nodes\n",
    "    ax.scatter(xy[:,0], xy[:,1], s=s, zorder=3)\n",
    "    \n",
    "    ## edges\n",
    "    if edges:\n",
    "        lines = [[pos[i], pos[j]] for (i,j) in g.edges]\n",
    "        lc = mc.LineCollection(lines, colors='grey', linewidths=lw)\n",
    "        ax.add_collection(lc)\n",
    "    ax.autoscale()\n",
    "    ax.margins(0.1)\n",
    "    plt.axis('equal')\n",
    "\n",
    "    if labels:\n",
    "        for i in g.nodes:\n",
    "            plt.text(pos[i][0], pos[i][1], g.nodes[i]['label'])\n",
    "    return ax\n",
    "#     plt.figure(figsize=figsize)\n",
    "#     nx.draw(\n",
    "#         g, \n",
    "#         pos=pos,\n",
    "#         node_size=10,\n",
    "#         width=0.5,\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subtree_sizes(tree, root):\n",
    "    tree = nx.bfs_tree(tree, source=root)\n",
    "    s = [len(nx.bfs_tree(tree, i).nodes) for i in tree.neighbors(root)]\n",
    "    total = sum(s)\n",
    "    return np.array(s)\n",
    "\n",
    "\n",
    "def normalize(node):\n",
    "    for prop in node:\n",
    "        if prop == 'pos':\n",
    "            pos = node[prop].replace('\"', '')\n",
    "            pos = pos.split(',')\n",
    "            pos = [float(pos[0]), float(pos[1])]\n",
    "            node[prop] = pos\n",
    "        else:\n",
    "            if type(node[prop]) == str:\n",
    "                node[prop] = node[prop].replace('\"', '')\n",
    "                \n",
    "            try:\n",
    "                node[prop] = int(node[prop])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    node[prop] = float(node[prop])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                print(node, prop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b06ce2",
   "metadata": {},
   "source": [
    "## Generate a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6883c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges2graph(lines, i2k=None, label2i=None):\n",
    "    pattern = re.compile('\"(.+)\" -- \"(.+)\"')\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    for i,line in enumerate(lines):\n",
    "        if len(line.strip()) > 0:\n",
    "            edge = re.findall(pattern, line)[0]\n",
    "            source, target = edge\n",
    "            nodes.update([source, target])\n",
    "            edges.add( (source, target) )\n",
    "    \n",
    "    if label2i is None:\n",
    "        label2i = {k:i for i,k in enumerate(nodes)}\n",
    "        i2k = list(range(len(nodes)))\n",
    "    g = nx.Graph()\n",
    "    \n",
    "    nodes = [dict(id=label2i[k], label=k) for i,k in enumerate(nodes)]\n",
    "    ids = [n['id'] for n in nodes]\n",
    "    g.add_nodes_from( zip(ids, nodes) )\n",
    "    \n",
    "    edges = [(i2k[label2i[e[0]]],i2k[label2i[e[1]]]) for e in edges]\n",
    "    g.add_edges_from(edges)\n",
    "    return g, i2k, label2i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fn in fns:\n",
    "#     with open(fn) as f:\n",
    "#         g, i2k, label2i = edges2graph(f.readlines())\n",
    "#         print(fn, len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fns = natsorted(glob('./data/txt/topics_faryad_500/*.txt'))\n",
    "# # fns = natsorted(glob('./data/txt/TopicsLayersData-0/*.txt'))\n",
    "# ## Reyan's level-weight setting\n",
    "# # nodeCount2levelweight = {\n",
    "# #     50: (1, 550),\n",
    "# #     100: (1, 500),\n",
    "# #     200: (2, 500),\n",
    "# #     300: (2, 450),\n",
    "# #     400:(2, 450),\n",
    "# #     500: (2, 450),\n",
    "# #     600: (3, 450), \n",
    "# #     700: (3, 450),\n",
    "# #     800: (3, 450),\n",
    "# #     1200: (3, 400),\n",
    "# #     1600: (4, 400),\n",
    "# #     2000: (4, 350),\n",
    "# #     2500: (5, 350),\n",
    "# #     3000: (5, 300),\n",
    "# #     3500: (6, 300),\n",
    "# #     4000: (6, 250),\n",
    "# #     4500: (7, 250),\n",
    "# #     5000: (8, 200)\n",
    "# # }\n",
    "\n",
    "# # nodeCount2levelweight = {\n",
    "# #     50: (1, 550),\n",
    "# #     100: (2, 500),\n",
    "# #     200: (3, 500), \n",
    "# #     500: (6, 450), 300: (4, 450), 400:(5, 450),\n",
    "# #     800: (9, 450), 600: (7, 450), 700: (8, 450),\n",
    "# #     1200: (10, 400),\n",
    "# #     1600: (11, 400),\n",
    "# #     2000: (12, 350),\n",
    "# #     2500: (13, 350),\n",
    "# #     3000: (14, 300),\n",
    "# #     3500: (15, 300),\n",
    "# #     4000: (16, 250),\n",
    "# #     4500: (17, 250),\n",
    "# #     5000: (18, 200)\n",
    "# # }\n",
    "\n",
    "# nodeCounts = sorted(list(nodeCount2levelweight.keys()))\n",
    "# levels = [nodeCount2levelweight[nc][0] for nc in nodeCounts]\n",
    "# weights = [nodeCount2levelweight[nc][1] for nc in nodeCounts]\n",
    "\n",
    "# list(zip(nodeCounts, levels, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339389ed",
   "metadata": {},
   "source": [
    "## Choose a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7210a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## ## fns = natsorted(glob('./data/txt/topics_refined/*.txt'))[1:]\n",
    "## ## fns = natsorted(glob('./data/txt/lastfm_refined/*.txt'))\n",
    "## ## fns = natsorted(glob('./data/txt/topics_steiner/*.txt'))\n",
    "## ## fns = natsorted(glob('./data/txt/lastfm_steiner/*.txt'))\n",
    "\n",
    "\n",
    "fns = natsorted(glob('./data/txt/lastfm/*.txt'))\n",
    "# fns = natsorted(glob('./data/txt/topics_faryad_8level/*.txt'))\n",
    "\n",
    "# fns = natsorted(glob('./data/txt/tol_graphs/*.txt'))[:8]\n",
    "# fns = natsorted(glob('./data/txt/tol_graphs/*.txt'))[:8]\n",
    "# fns = [\n",
    "#     f'./data/txt/tol_graphs/{fn}' for fn in \n",
    "#     [\n",
    "#         'Graph_0.txt', \n",
    "#         'Graph_1.txt', \n",
    "#         'Graph_2_600.txt', \n",
    "#         'Graph_2.txt', \n",
    "#         'Graph_3.txt', \n",
    "#         'Graph_4_1600.txt', \n",
    "#         'Graph_4_2000.txt',\n",
    "#         'Graph_4.txt',\n",
    "#     ]\n",
    "# ]\n",
    "#fns = natsorted(glob('./data/txt/math_genealogy/*.txt'))[:4]\n",
    "# fns = [\n",
    "#     f'./data/txt/math_genealogy/{fn}' for fn in \n",
    "#     [\n",
    "#       'Graph_0.txt', \n",
    "#       'Graph_1.txt', \n",
    "#       'Graph_2_600.txt', \n",
    "#       'Graph_2.txt', \n",
    "#       'Graph_3_1200.txt', \n",
    "#       'Graph_3_1600.txt', \n",
    "#       'Graph_3_2000.txt', \n",
    "#       'Graph_3.txt',\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "levels = list(range(1, len(fns)+1))\n",
    "maxLevel = max(*levels)\n",
    "\n",
    "## linear increment\n",
    "baseWeight = 200\n",
    "if 'topics_steiner' in fns[0]:\n",
    "    increment = 50\n",
    "elif 'tol_graphs' in fns[0]:\n",
    "    increment = 50\n",
    "else:\n",
    "    increment = 50\n",
    "weights = [baseWeight+(maxLevel-l)*increment for l in levels]\n",
    "weights = [w/200 for w in weights]\n",
    "\n",
    "## exponential increment\n",
    "# baseWeight = 1\n",
    "# maxWeight = 1\n",
    "# incrementFactor = maxWeight**(1/(maxLevel-1))\n",
    "# weights = [baseWeight*incrementFactor**(maxLevel-l) for l in levels]\n",
    "\n",
    "list(zip(fns,levels,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f7b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_largest = natsorted(glob('./data/txt/topics_large/*.txt'))[-1]\n",
    "# print(fn_largest)\n",
    "# with open(fn_largest) as f:\n",
    "#     print(len(f.readlines())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5860c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(fns[-1]) as f:\n",
    "    \n",
    "#     nodeCount = len(g)\n",
    "#     level = levels[-1]\n",
    "#     weight = weights[-1]\n",
    "#     print(fns[-1], level, nodeCount, weight)\n",
    "#     for n in g.nodes:\n",
    "#         g.nodes[n]['level'] = level\n",
    "#         g.nodes[n]['nodeCount'] = nodeCount\n",
    "#         g.nodes[n]['weight'] = weight\n",
    "        \n",
    "#     for e in g.edges:\n",
    "#         g.edges[e]['level'] = level\n",
    "#         g.edges[e]['weight'] = weight\n",
    "\n",
    "# for fn, level, weight in list(fn_level_weight)[:-1][::-1]:\n",
    "for i, (fn, level, weight) in list(enumerate(zip(fns, levels, weights)))[::-1]:\n",
    "    \n",
    "    with open(fn) as f:\n",
    "        if level == maxLevel:\n",
    "            subgraph, i2k, label2i = edges2graph(f.readlines())\n",
    "            g = subgraph\n",
    "        else:\n",
    "            subgraph,_,_ = edges2graph(f.readlines(), i2k, label2i)\n",
    "        nodeCount = len(subgraph)\n",
    "        print(fn, level, nodeCount, weight)\n",
    "    \n",
    "        for n in subgraph.nodes:\n",
    "            g.nodes[n]['level'] = level\n",
    "            g.nodes[n]['nodeCount'] = nodeCount\n",
    "            g.nodes[n]['weight'] = weight\n",
    "\n",
    "        for e in subgraph.edges:\n",
    "            g.edges[e]['level'] = level\n",
    "            g.edges[e]['weight'] = weight\n",
    "\n",
    "\n",
    "print('all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight='weight')\n",
    "d = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = dk[0]\n",
    "    target_dist = dk[1]\n",
    "    d[source,:] = [target_dist[i] for i in range(len(g.nodes))]\n",
    "    \n",
    "    \n",
    "print('k-hop all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight=1)\n",
    "hops = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = dk[0]\n",
    "    target_dist = dk[1]\n",
    "    hops[source,:] = [target_dist[i] for i in range(len(g.nodes))]\n",
    "\n",
    "fn = fns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e173e41",
   "metadata": {},
   "source": [
    "## Initial Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fb8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fan(nodes, \n",
    "        origin=[0,0], radii=[], \n",
    "        phaseCenter=0, phaseRange=np.pi, \n",
    "        weights=[1,1], \n",
    "        mode='random'):\n",
    "    pos = {}\n",
    "    phases = {}\n",
    "    ranges = {}\n",
    "    n = len(nodes)\n",
    "    cos, sin = np.cos, np.sin\n",
    "    \n",
    "    weightTotal = sum(weights)\n",
    "    weights = [w/weightTotal for w in weights]\n",
    "    \n",
    "    nr = sorted(zip(nodes, weights, radii), key=lambda x:x[1])\n",
    "    \n",
    "    \n",
    "    if mode == 'center':\n",
    "        ## centralize heavy sub trees\n",
    "        nr2 = []\n",
    "        for i in list(range(len(nr)))[::-1]:\n",
    "            if i%2 == 0:\n",
    "                nr2.append(nr[i])\n",
    "            else:\n",
    "                nr2.insert(0, nr[i])\n",
    "    elif mode == 'polar':\n",
    "        ## polarize heavy sub trees\n",
    "        nr2 = []\n",
    "        for i in range(len(nr)):\n",
    "            if i%2 == 0:\n",
    "                nr2.append(nr[i])\n",
    "            else:\n",
    "                nr2.insert(0, nr[i])\n",
    "    elif mode == 'random':\n",
    "        shuffle(nr)\n",
    "        nr2 = nr\n",
    "    elif mode == 'interleave':\n",
    "        a = nr[::2]\n",
    "        b = nr[1::2][::-1]\n",
    "        if len(a)==len(b):\n",
    "            nr2 = sum(zip(a,b), tuple())\n",
    "        else:\n",
    "            nr2 = sum(zip(a,b+[-1,]), tuple())[:-1]\n",
    "            \n",
    "    elif mode == 'ordered':\n",
    "        nr2 = nr\n",
    "        \n",
    "    nodes, weights, radii = zip(*nr2)\n",
    "    \n",
    "    weightCumSum = [sum(weights[:i]) for i in range(len(weights)+1)]\n",
    "    for i in range(n):\n",
    "        angle_offset = (weightCumSum[i]+weightCumSum[i+1])/2 * phaseRange\n",
    "        angle_i = phaseCenter - phaseRange/2 + angle_offset\n",
    "        ri = radii[i]\n",
    "        pos[nodes[i]] = [origin[0] + ri*cos(angle_i), origin[1] + ri*sin(angle_i)]\n",
    "        phases[nodes[i]] = angle_i\n",
    "        ranges[nodes[i]] = weights[i] * phaseRange * 0.9\n",
    "    return pos, phases, ranges\n",
    "\n",
    "\n",
    "def radial_layout(g, root=None, mode='center', origin=[0,0], phase0=0, range0=np.pi*2):\n",
    "    g0 = g\n",
    "    g = nx.bfs_tree(g, source=root)\n",
    "    pos = {}\n",
    "    phases = {}\n",
    "    ranges = {}\n",
    "    depth_from_root = nx.shortest_path_length(g, root)\n",
    "    if root is None:\n",
    "        root = next(iter(g.nodes))\n",
    "    pos[root] = origin\n",
    "    phases[root] = phase0\n",
    "    ranges[root] = range0\n",
    "    roots = [root, ]\n",
    "    depth = 1\n",
    "    while len(pos) < len(g.nodes):\n",
    "        newRoots = []\n",
    "        for root in roots:\n",
    "            if mode=='ordered':\n",
    "                neighbors = [n for n in g0.nodes[root]['neighbor_order'] if n not in pos]\n",
    "            else:\n",
    "                neighbors = [n for n in g.neighbors(root) if n not in pos]\n",
    "            if len(neighbors) > 0:\n",
    "                edge_lengths = [g0.edges[(root, n)]['weight'] for n in neighbors]\n",
    "                subTreeSizes = [len(nx.bfs_tree(g, i).nodes) for i in neighbors]\n",
    "                degrees = [g.degree[i] for i in neighbors]\n",
    "                depths = [depth_from_root[i] for i in neighbors]\n",
    "#                 weights = [(x*z/y**2) for x, y, z in zip(degrees, depths, subTreeSizes)]\n",
    "                weights = [z for x, y, z in zip(degrees, depths, subTreeSizes)]\n",
    "#                 neighborSizes = [len(list(g0.neighbors(i))) for i in neighbors]\n",
    "                newRoots += neighbors\n",
    "                newPos, newPhases, newRanges = fan(\n",
    "                    neighbors, \n",
    "                    mode=mode,\n",
    "#                     origin=pos[root], radii=edge_lengths, #mode: Reyan\n",
    "                    origin=origin, radii=[depth for e in edge_lengths],#mode: mw\n",
    "                    phaseCenter=phases[root], \n",
    "                    phaseRange=ranges[root], \n",
    "                    weights=weights,\n",
    "                )\n",
    "                pos.update(newPos)\n",
    "                phases.update(newPhases)\n",
    "                ranges.update(newRanges)\n",
    "        roots = newRoots\n",
    "        depth+=1\n",
    "    return pos\n",
    "\n",
    "\n",
    "def rotate(pos0, theta=0):\n",
    "    cos = math.cos(theta)\n",
    "    sin = math.sin(theta)\n",
    "    pos = {}\n",
    "    for k in pos0:\n",
    "        p = pos0[k]\n",
    "        pos[k] = (p[0]*cos-p[1]*sin, p[0]*sin+p[1]*cos)\n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "def neighbor_order(nodeId, parentId, neighbors, pos):\n",
    "    v = np.array([pos[i] for i in neighbors]) - np.array([pos[nodeId]])\n",
    "    a = np.angle(v[:,0] + 1j * v[:,1])\n",
    "    order = [neighbors[o] for o in np.argsort(a)]\n",
    "    if parentId is not None:\n",
    "        order = np.roll(order, -order.index(parentId))\n",
    "    return order\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # root = list(g.nodes)[np.argmin(d.max(axis=1))] ##center node\n",
    "# root = nx.center(g)[0]\n",
    "# root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ca259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "init_layout = 'radial'\n",
    "# init_layout = 'sfdp-ordered-radial'\n",
    "# init_layout = 'sfdp'\n",
    "\n",
    "\n",
    "# # pos0 = nx.layout.planar_layout(g, scale=40)\n",
    "# # pos0 = graphviz_layout(g, prog=\"dot\", root=list(g.nodes)[0])\n",
    "# # pos0 = graphviz_layout(g, prog='twopi')\n",
    "\n",
    "t0 = time()\n",
    "if init_layout == 'sfdp':\n",
    "    g1 = nx.Graph(g)\n",
    "    for i in g1.nodes:\n",
    "        g1.nodes[i]['label'] = ''\n",
    "    pos0 = graphviz_layout(g1, prog='sfdp')\n",
    "    \n",
    "    \n",
    "elif init_layout == 'radial':\n",
    "    root = list(g.nodes)[np.argmin(d.max(axis=1))] ##large-depth node\n",
    "#     root = choice(list(g.nodes)) ##random node\n",
    "    \n",
    "#     root = nx.center(g)[0]\n",
    "#     root = 1949 ##tree-of-life 3000-nodes\n",
    "#     root = 1143\n",
    "    pos0 = radial_layout(g, root, mode='center')\n",
    "#     pos0 = rotate(pos0, -math.pi*0.5)\n",
    "\n",
    "\n",
    "elif init_layout == 'sfdp-ordered-radial':\n",
    "    \n",
    "    \n",
    "    ##remove label to avoid parsing bug of sfdp\n",
    "    g1 = nx.Graph(g)\n",
    "    for i in g1.nodes:\n",
    "        g1.nodes[i]['label'] = '' \n",
    "        \n",
    "    pos_sfdp = graphviz_layout(g1, prog='sfdp')\n",
    "    draw(g, pos_sfdp, s=1, lw=1, labels=False, figsize=[8,8])\n",
    "#     center = np.array(list(pos_sfdp.values())).mean(0)\n",
    "#     root = min([p for p in pos_sfdp.items()], key=lambda x:np.linalg.norm(x[1]-center))[0]\n",
    "    root = list(g.nodes)[np.argmin(d.max(axis=1))] ##large-depth node\n",
    "    root = 1949 ##tree-of-life 3000-nodes\n",
    "#     root = nx.center(g)[0]\n",
    "    bfs = nx.bfs_tree(g, root)\n",
    "    for nodeId in g:\n",
    "        try:\n",
    "            parentId = next(bfs.predecessors(nodeId))\n",
    "        except StopIteration:\n",
    "            parentId = None\n",
    "        neighbors = list(g.neighbors(nodeId))\n",
    "        g.nodes[nodeId]['neighbor_order'] = neighbor_order(nodeId, parentId, neighbors, pos_sfdp)\n",
    "    \n",
    "    pos0 = radial_layout(g, root, mode='ordered')\n",
    "    \n",
    "\n",
    "\n",
    "dt = time() - t0\n",
    "print(f'{dt} sec')\n",
    "\n",
    "\n",
    "# pos0 = rotate(pos0, math.pi/180* 80)\n",
    "draw(g, pos0, s=1, lw=1, labels=False, figsize=[24,24])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k2i = {v:k for k,v in enumerate(i2k)}\n",
    "# k2i[root]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center = np.array(list(pos0.values())).mean(0)\n",
    "# root = min([p for p in pos0.items()], key=lambda x:np.linalg.norm(x[1]-center))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d800ef",
   "metadata": {},
   "source": [
    "## New Ordering of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d964872",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_order = list(g.nodes)\n",
    "bfs = nx.bfs_tree(g, root)\n",
    "\n",
    "### list of node ids\n",
    "\n",
    "\n",
    "# if ('math-genealogy' in fn \n",
    "#     or 'topics-800' in fn\n",
    "#     or 'covid' in fn\n",
    "#    ):\n",
    "    \n",
    "# print('no re-ordering')\n",
    "## no re-ordering\n",
    "# node_order = list(g.nodes)\n",
    "\n",
    "## order preserving re-sort according to level\n",
    "# id2level = {i: g.nodes[i]['level'] for i in g.nodes}\n",
    "# nodeorder_level_pairs = [(i,id2level[i]) for i in node_order]\n",
    "# node_order = [n[0] for n in sorted(nodeorder_level_pairs, key=lambda x:x[1])]\n",
    "\n",
    "##bfs ordering\n",
    "node_order = list(bfs) \n",
    "\n",
    "\n",
    "\n",
    "# else:\n",
    "#     #max degree node\n",
    "#     print('max degree node re-ordering')\n",
    "#     degree = list(g.degree)\n",
    "#     degree = list(zip(range(len(degree)), degree))\n",
    "#     max_degree_node = max(degree, key=lambda x:x[1][1])\n",
    "#     start = max_degree_node[1][0]\n",
    "#     bfs = nx.bfs_tree(g, start)\n",
    "#     node_order = list(bfs) \n",
    "    \n",
    "# #     # random node, bfs\n",
    "# #     start = next(iter(g.nodes.keys()))\n",
    "# #     bfs = nx.bfs_tree(g, start)\n",
    "# #     node_order = list(bfs) \n",
    "\n",
    "# #     #dfs\n",
    "# #     node_order = list(nx.dfs_preorder_nodes(g, start))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee2848",
   "metadata": {},
   "source": [
    "## load dot as networkx graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e347fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = pos0.copy()\n",
    "# ideal_edge_length = {\n",
    "#     e: g.edges[e]['weight'] \n",
    "#     for e in g.edges\n",
    "# }\n",
    "# actual_edge_length = {\n",
    "#     (p0,p1): np.linalg.norm(np.array(pos[p1])-np.array(pos[p0]))\n",
    "#     for (p0,p1) in g.edges\n",
    "# }\n",
    "# num = np.sum([ideal_edge_length[k]*actual_edge_length[k] for k in g.edges])\n",
    "# den = np.sum([actual_edge_length[k]**2 for k in g.edges])\n",
    "# s = num / den\n",
    "# print(f's = {s}')\n",
    "\n",
    "# pos = {k:np.array(v)*s for k,v in pos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5763bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos0.copy()\n",
    "s = 1\n",
    "pos = {k:list(np.array(v)*s) for k,v in pos.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f68e0",
   "metadata": {},
   "source": [
    "## to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = 'linear'\n",
    "\n",
    "dir_out, name = str(Path(fn).parent), Path(fn).stem\n",
    "dir_out = dir_out.replace('dot', 'json').replace('txt', 'json')\n",
    "dir_out += f'_{suffix}'\n",
    "fn_out = dir_out + '/'+ name\n",
    "fn_out += f'-{int(time())}'\n",
    "\n",
    "if not Path(dir_out).exists():\n",
    "    os.makedirs(Path(dir_out))\n",
    "else:\n",
    "    print(Path(dir_out), 'exists')\n",
    "fn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71772ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in g.nodes:\n",
    "    if 'neighbor_order' in g.nodes[n]:\n",
    "        del g.nodes[n]['neighbor_order']\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17593a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###graph to list\n",
    "nodes = {k: g.nodes[k] for k in g.nodes}\n",
    "edges = [[e[0], e[1], g.edges[e]] for e in g.edges]\n",
    "\n",
    "nodes = [{\n",
    "    'id': node_order[i],\n",
    "    'index': i,\n",
    "    'x': float(pos[node_order[i]][0]),\n",
    "    'y': float(pos[node_order[i]][1]),\n",
    "    'neighbors': list(nx.neighbors(g, node_order[i])),\n",
    "    'perplexity': len(list(nx.neighbors(g, node_order[i]))),\n",
    "    **nodes[node_order[i]]\n",
    "} for i in range(len(nodes))]\n",
    "\n",
    "edges = [{\n",
    "    'source': e[0],\n",
    "    'target': e[1],\n",
    "    **e[2]\n",
    "} for e in edges]\n",
    "\n",
    "\n",
    "\n",
    "##store the position & perplexity\n",
    "for i,node in enumerate(nodes):\n",
    "    try: \n",
    "        parent = next(bfs.predecessors(node['id']))\n",
    "    except StopIteration:\n",
    "        parent = None\n",
    "    node['parent'] = parent\n",
    "\n",
    "hopThresh = 6\n",
    "virtual_edges = []\n",
    "for i in tqdm(range(len(nodes))):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        if d[i,j] == 0:\n",
    "            print(f'[warning] d[{i},{j}] = 0')\n",
    "        else:\n",
    "            if hops[i,j] < hopThresh or random() < 1:\n",
    "                dij = d[i,j]\n",
    "                e = {\n",
    "                    'source': i2k[i],\n",
    "                    'target': i2k[j],\n",
    "                    'weight': dij,\n",
    "                    'hops': hops[i,j]\n",
    "                }\n",
    "                virtual_edges.append(e)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "## option 1: nodes, edges, and virtualEdges with properties\n",
    "# with open(fn_out, 'w') as f:\n",
    "#     json.dump(dict(\n",
    "#         edges = edges, \n",
    "#         virtual_edges = virtual_edges, \n",
    "#         nodes=nodes\n",
    "#     ), f, indent=2)\n",
    "# print('done')\n",
    "\n",
    "\n",
    "## option 2: properties as arrays\n",
    "res = {}\n",
    "for k in nodes[0]:\n",
    "    print(k)\n",
    "    res[f'node_{k}'] = [n[k] for n in nodes]\n",
    "for k in edges[0]:\n",
    "    res[f'edge_{k}'] = [e[k] for e in edges]\n",
    "\n",
    "print(fn_out)\n",
    "with open(fn_out+'-min.json', 'w') as f:\n",
    "    json.dump(res, f, indent=2)\n",
    "    \n",
    "for k in virtual_edges[0]:\n",
    "    res[f'virtual_edge_{k}'] = [ve[k] for ve in virtual_edges]\n",
    "\n",
    "print(f'writing {fn_out}.json...')\n",
    "with open(fn_out+'.json', 'w') as f:\n",
    "    json.dump(res, f, indent=2)\n",
    "\n",
    "print('done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0377ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##debug\n",
    "\n",
    "for k,v in res.items():\n",
    "    print(k, type(res[k][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf43265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/json/TopicsLayersData-0/Graph_5000-nodes-3.json') as f:\n",
    "#     j3 = json.load(f)\n",
    "# with open('data/json/TopicsLayersData-0/Graph_5000.json') as f:\n",
    "#     j = json.load(f)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodeIds = [n['id'] for n in nodes]\n",
    "# nodeLabels = [n['label'] for n in nodes]\n",
    "# nodeLevels = [n['level'] for n in nodes]\n",
    "# nodeXs = [n['x'] for n in nodes]\n",
    "# nodeYs = [n['y'] for n in nodes]\n",
    "# nodePerplexities = [n['perplexity'] for n in nodes]\n",
    "# nodeParents = [n['parent'] for n in nodes]\n",
    "# nodeNeighbors = [n['neighbors'] for n in nodes]\n",
    "# nodeNodeCount = [n['nodeCount'] for n in nodes]\n",
    "# nodeWeight = [n['weight'] for n in nodes]\n",
    "\n",
    "# edgeSources = [e['source'] for e in edges]\n",
    "# edgeTargets = [e['target'] for e in edges]\n",
    "# edgeLevels = [e['level'] for e in edges]\n",
    "# edgeWeights = [e['weight'] for e in edges]\n",
    "\n",
    "# virtualEdgeSources = [e['source'] for e in virtual_edges]\n",
    "# virtualEdgeTargets = [e['target'] for e in virtual_edges]\n",
    "# virtualEdgeWeights = [e['weight'] for e in virtual_edges]\n",
    "# virtualEdgeHops = [e['hops'] for e in virtual_edges]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bb197f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30a3140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5257175",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fa067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "\n",
    "def json_to_errors(fn, fn_node, shouldScale=False):\n",
    "    with open(fn) as f:\n",
    "        data = json.load(f)\n",
    "    with open(fn_node) as f:\n",
    "        nodes = json.load(f)\n",
    "\n",
    "    label_to_id = {l:i for l,i in zip(data['node_label'], data['node_id'])}\n",
    "    id_to_label = {v:k for k,v in label_to_id.items()}\n",
    "\n",
    "    my_edges = [[id_to_label[i], id_to_label[j]] for i,j in zip(data['edge_source'], data['edge_target'])]\n",
    "    edge_distance = {i:w for i,w in enumerate(data['edge_weight'])}\n",
    "#     nodes_to_levels = {label: level for label, level in zip(data['node_label'], data['node_level'])}\n",
    "\n",
    "    crd_x = {n['id']:n['x'] for n in nodes}\n",
    "    crd_y = {n['id']:n['y'] for n in nodes}\n",
    "\n",
    "#     label_to_xy = {l: (crd_x[i], crd_y[i]) for l,i in label_to_id.items()}\n",
    "    xy = np.array([[crd_x[k], crd_y[k]] for k in crd_x])\n",
    "\n",
    "    lines = [\n",
    "        [(crd_x[label_to_id[l1]], crd_y[label_to_id[l1]]), \n",
    "        (crd_x[label_to_id[l2]], crd_y[label_to_id[l2]])] \n",
    "        for l1,l2 in my_edges\n",
    "    ]\n",
    "\n",
    "    edge_coords = np.array(lines)\n",
    "    s, t = edge_coords[:, 0], edge_coords[:, 1]\n",
    "    actual_length = np.linalg.norm(s - t, axis=1)\n",
    "    ideal_length = np.array(list(edge_distance.values()))\n",
    "\n",
    "    if shouldScale:\n",
    "        num = np.sum(ideal_length**2/actual_length)\n",
    "        den = np.sum(ideal_length)\n",
    "        s = num / den\n",
    "    else:\n",
    "        s = 1\n",
    "    relative_error = (actual_length*s - ideal_length) / ideal_length\n",
    "    \n",
    "    return lines, relative_error\n",
    "\n",
    "\n",
    "\n",
    "def fn_coord_to_xy(fn_coord):\n",
    "    with open(fn_coord) as f:\n",
    "        xy = [l.split()[:2] for l in f]\n",
    "        xy = [(float(x), float(y)) for x,y in xy]\n",
    "    return xy\n",
    "\n",
    "\n",
    "\n",
    "def fn_edge_to_lines(fn_edge, xy):\n",
    "    \n",
    "    with open(fn_edge) as f:\n",
    "        f.readline()##skip first (comment) line\n",
    "        f.readline()##skip second line\n",
    "        reads = [l.split()[:3] for l in f]\n",
    "        ideal_length = [float(r[2]) for r in reads]\n",
    "        edges = [r[:2] for r in reads]\n",
    "        edges = [(int(i), int(j)) for i,j in edges]\n",
    "        lines = [(xy[i-1], xy[j-1]) for i,j in edges]\n",
    "    return lines, ideal_length\n",
    "\n",
    "\n",
    "\n",
    "def txt_to_errors(fn_coord, fn_edge, shouldScale=False):\n",
    "    ## for large graphs\n",
    "    \n",
    "    xy = fn_coord_to_xy(fn_coord)\n",
    "    lines, ideal_length = fn_edge_to_lines(fn_edge, xy)\n",
    "        \n",
    "    edge_coords = np.array(lines)\n",
    "    s, t = edge_coords[:, 0], edge_coords[:, 1]\n",
    "    actual_length = np.linalg.norm(s - t, axis=1)\n",
    "    ideal_length = np.array(ideal_length)\n",
    "    if shouldScale:\n",
    "        num = np.sum(ideal_length**2/actual_length)\n",
    "        den = np.sum(ideal_length)\n",
    "        s = num / den\n",
    "    else:\n",
    "        s = 1\n",
    "    relative_error = (actual_length*s - ideal_length) / ideal_length\n",
    "    return lines, relative_error\n",
    "\n",
    "\n",
    "    \n",
    "def error_analysis(lines, relative_error, \n",
    "                   figsize=[8,15], height_ratios=[3,1], \n",
    "                   xlim=None, ylim=None):\n",
    "    rows, cols = 2, 1\n",
    "    gs = gridspec.GridSpec(rows, cols, width_ratios=[1,], height_ratios=height_ratios)\n",
    "    gs.update(left=0.05, right=0.95, wspace=0.1, hspace=0.1)\n",
    "\n",
    "    vmax = 1\n",
    "    cm = plt.cm.get_cmap('coolwarm_r')\n",
    "\n",
    "    # Plot histogram.\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    ax = plt.subplot(gs[0,0])\n",
    "    # ax.scatter(xy[:,0], xy[:,1], s=1, zorder=2)\n",
    "    lc = mc.LineCollection(lines, \n",
    "                           colors=[cm((e+vmax) / (vmax*2)) for e in relative_error], \n",
    "                           linewidths=1)\n",
    "    ax.add_collection(lc)\n",
    "    ax.autoscale()\n",
    "    ax.margins(0.1)\n",
    "    plt.axis('equal')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "        \n",
    "    plt.subplot(gs[1,0])\n",
    "    n, bins, patches = plt.hist(relative_error, color='green', bins=60)\n",
    "    bin_centers = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # scale values to interval [0,1]\n",
    "    col = (bin_centers + vmax ) / (vmax*2)\n",
    "\n",
    "    for c, p in zip(col, patches):\n",
    "        plt.setp(p, 'facecolor', cm(c))\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.xlabel('relative error')\n",
    "    plt.ylabel('# edges')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_in = './data/json/topics-5000-low-degree/old/'\n",
    "# fn = 'topics-8-sfdp'\n",
    "# version = 16\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------\n",
    "# paper topics\n",
    "# dir_in = './data/json/TopicsLayersData-0'\n",
    "# fn = 'Graph_5000'\n",
    "# version = 3\n",
    "\n",
    "# paper lastfm\n",
    "# dir_in = './data/json/lastfm/'\n",
    "# fn = 'Graph_8'\n",
    "# version = 2\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "##demo topics\n",
    "# dir_in = './data/json/TopicsLayersData-0'\n",
    "# fn = 'Graph_5000-radial'\n",
    "# version = 7\n",
    "\n",
    "##demo lastfm\n",
    "# dir_in = './data/json/lastfm/'\n",
    "# fn = 'Graph_8'\n",
    "# version = 12\n",
    "\n",
    "#-------------------------------------------\n",
    "## demo, post-pacific-vis submission\n",
    "\n",
    "##topics\n",
    "# fn = './data/json/topics_refined/Graph_5000-min.json'\n",
    "# fn_node = './data/json/topics_refined/Graph_5000-nodes-3.json'\n",
    "\n",
    "# ##lastfm\n",
    "# fn = './data/json/lastfm_refined/Graph_8_2587-min.json'\n",
    "# fn_node = './data/json/lastfm_refined/Graph_8_2587-nodes-1.json'\n",
    "\n",
    "#-------------------------------------------\n",
    "## VIS 2021 submission\n",
    "shouldScale = False\n",
    "\n",
    "## CG\n",
    "\n",
    "# fn = 'data/json/lastfm_linear/Graph_8-1615803307-min.json'\n",
    "# fn_node = './data/json/lastfm_linear/Graph_8-1615803307-nodes-1.json'\n",
    "# lines, relative_error = json_to_errors(fn, fn_node, shouldScale=shouldScale)\n",
    "\n",
    "# fn = 'data/json/topics_faryad_8level_linear/Graph_5000-1615834916-min.json'\n",
    "# fn_node = 'data/json/topics_faryad_8level_linear/Graph_5000-1615834916-nodes-3.json'\n",
    "# lines, relative_error = json_to_errors(fn, fn_node, shouldScale=shouldScale)\n",
    "\n",
    "# fn = 'data/json/tol_graphs_linear/Graph_4-1615872482-min.json'\n",
    "# fn_node = 'data/json/tol_graphs_linear/Graph_4-1615872482-nodes-1.json'\n",
    "# lines, relative_error = json_to_errors(fn, fn_node, shouldScale=shouldScale)\n",
    "\n",
    "## \n",
    "def js_to_errors(fn, level_to_dist, shouldScale=False):\n",
    "#     g = read_graph(graph_dir)\n",
    "    data = read_js(fn)\n",
    "    crd_x, crd_y = data['crd_x'], data['crd_y']\n",
    "    label_to_id = data['label_to_id']\n",
    "    my_edges = data['my_edges']\n",
    "    \n",
    "    nodes_to_levels = data['nodes_to_levels']\n",
    "    edge_distance = {\n",
    "        i:level_to_dist[\n",
    "            max(\n",
    "                nodes_to_levels[my_edges[i][0]], \n",
    "                nodes_to_levels[my_edges[i][1]]\n",
    "            )]\n",
    "        for i in range(len(my_edges))\n",
    "    }\n",
    "    xy = np.array([[crd_x[k], crd_y[k]] for k in crd_x])\n",
    "    lines = [\n",
    "        [(crd_x[str(label_to_id[l1])], crd_y[str(label_to_id[l1])]), \n",
    "        (crd_x[str(label_to_id[l2])], crd_y[str(label_to_id[l2])])] \n",
    "        for l1,l2 in my_edges\n",
    "    ]\n",
    "\n",
    "    edge_coords = np.array(lines)\n",
    "    s, t = edge_coords[:, 0], edge_coords[:, 1]\n",
    "    actual_length = np.linalg.norm(s - t, axis=1)\n",
    "    ideal_length = np.array(list(edge_distance.values()))\n",
    "\n",
    "    if shouldScale:\n",
    "        num = np.sum(ideal_length**2/actual_length)\n",
    "        den = np.sum(ideal_length)\n",
    "        s = num / den\n",
    "    else:\n",
    "        s = 1\n",
    "    relative_error = (actual_length*s - ideal_length) / ideal_length\n",
    "    \n",
    "    return lines, relative_error\n",
    "\n",
    "\n",
    "def read_js(fn_in, center=True, scale=1):\n",
    "    data_in = {}\n",
    "    with open(fn_in) as f0:\n",
    "        for line in f0:\n",
    "            if line.startswith('//'):\n",
    "                continue\n",
    "            var_name, value = line.split(' = ')\n",
    "            value = value.strip()\n",
    "            try:\n",
    "                value = json.loads(value)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(e)\n",
    "                print(repr(value[e.colno-5:e.colno+20]))\n",
    "                return e\n",
    "            data_in[var_name] = value\n",
    "\n",
    "    print(data_in.keys())\n",
    "    return data_in\n",
    "\n",
    "level_to_dist = {i:200+50*(8-i) for i in range(1,9)}\n",
    "# fn = '../mlgd/map_generator/in/lastfm-DELG.json'\n",
    "# lines, relative_error = js_to_errors(fn, level_to_dist, shouldScale=shouldScale)\n",
    "# fn = '../mlgd/map_generator/in/topics-DELG.json'\n",
    "# lines, relative_error = js_to_errors(fn, level_to_dist, shouldScale=shouldScale)\n",
    "fn = '../mlgd/map_generator/in/tol-DELG.json'\n",
    "lines, relative_error = js_to_errors(fn, level_to_dist, shouldScale=shouldScale)\n",
    "\n",
    "## BT\n",
    "# fn_coord = 'data/large/topics/Graph_28.top.txt.weighted.mtxBatchPrEL128PARAOUT0.txt'\n",
    "# fn_edge = 'data/large/topics/Graph_28.top.txt.weighted.mtx'\n",
    "# lines, relative_error = txt_to_errors(fn_coord, fn_edge, shouldScale=shouldScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f851c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pygraphviz\n",
    "\n",
    "import pygraphviz as pgv\n",
    "\n",
    "dot_fn = './data/external/in/lastfm/direct_lastfm_8.dot'\n",
    "gv = pgv.AGraph(dot_fn, strict=False, directed=False)\n",
    "\n",
    "G = nx.Graph(gv)\n",
    "for i, node in tqdm(G.nodes(data=True)):\n",
    "    node['pos'] = node['pos'].split(',')\n",
    "    node['pos'] = [float(node['pos'][0]), float(node['pos'][1])]\n",
    "    \n",
    "pos = {i:node['pos'] for i,node in G.nodes(data=True)}\n",
    "draw(G, pos, figsize=[4,4], s=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633a4fa3",
   "metadata": {},
   "source": [
    "## grap attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = natsorted(pos.keys())\n",
    "node_x = [pos[n][0] for n in node_id]\n",
    "node_y = [pos[n][1] for n in node_id]\n",
    "node_index = list(range(len(node_id)))\n",
    "node_level = [1] * len(node_id)\n",
    "node_label = [G.nodes[i]['label'] for i in G.nodes]\n",
    "\n",
    "edges = G.edges\n",
    "edge_source = [int(e[0]) for e in edges]\n",
    "edge_target = [int(e[1]) for e in edges]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "out_fn = 'data/external/lastfm-CIR.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2e845",
   "metadata": {},
   "source": [
    "## write output json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6a185",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dict(\n",
    "    node_x=node_x,\n",
    "    node_y=node_y,\n",
    "    node_id=node_id,\n",
    "    node_index=node_index,\n",
    "    node_label=node_label,\n",
    "\n",
    "    node_level=node_level, \n",
    "\n",
    "    edge_source=edge_source,\n",
    "    edge_target=edge_target,\n",
    ")\n",
    "with open(out_fn, 'w') as f:\n",
    "    json.dump(out, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
