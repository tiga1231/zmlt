{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import re\n",
    "import json\n",
    "import math\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# import pydot\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx.drawing.nx_pydot import read_dot\n",
    "\n",
    "from matplotlib import collections  as mc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-colorblind')\n",
    "from IPython.display import clear_output\n",
    "\n",
    "nodePattern = re.compile('^(\\d+) ')\n",
    "edgePattern = re.compile('^(\\d+) -- (\\d+)')\n",
    "attrsPattern = re.compile('\\[(.+)\\]')\n",
    "\n",
    "def isNode(line):\n",
    "    return '--' not in line\n",
    "\n",
    "\n",
    "def processAttrs(line):\n",
    "    attrs = attrsPattern.findall(line)\n",
    "    if len(attrs) > 0:\n",
    "        attrs = attrs[0].split(',')\n",
    "    attrs = [a.split('=') for a in attrs]\n",
    "    attrs = [[a[0].strip(), a[1].replace('\"','').strip()] for a in attrs]\n",
    "    for a in attrs:\n",
    "        try:\n",
    "            a[1] = int(a[1])\n",
    "        except ValueError:\n",
    "            try:\n",
    "                a[1] = float(a[1])\n",
    "            except:\n",
    "                pass\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def processEdge(line):\n",
    "    finding = edgePattern.findall(line)[0]\n",
    "    source, target = finding[:2]\n",
    "    source, target = int(source), int(target)\n",
    "    attrs = processAttrs(line)\n",
    "    return dict(attrs, source=source, target=target)\n",
    "\n",
    "\n",
    "def processNode(line):\n",
    "    nodeId = int(line.split(' ')[0])\n",
    "    nodeAttrs = processAttrs(line)\n",
    "    return dict(nodeAttrs, id=nodeId)\n",
    "\n",
    "\n",
    "def draw(g, pos, edges=True, labels=True, figsize=[8,8], s=2, lw=0.5):\n",
    "    xy = np.array(list([pos[k] for k in g.nodes]))\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "    ## nodes\n",
    "    ax.scatter(xy[:,0], xy[:,1], s=s, zorder=3)\n",
    "    \n",
    "    ## edges\n",
    "    if edges:\n",
    "        lines = [[pos[i], pos[j]] for (i,j) in g.edges]\n",
    "        lc = mc.LineCollection(lines, colors='grey', linewidths=lw)\n",
    "        ax.add_collection(lc)\n",
    "    ax.autoscale()\n",
    "    ax.margins(0.1)\n",
    "#     plt.axis('equal')\n",
    "\n",
    "    if labels:\n",
    "        for i in g.nodes:\n",
    "            plt.text(pos[i][0], pos[i][1], g.nodes[i]['label'])\n",
    "    plt.show()\n",
    "\n",
    "#     plt.figure(figsize=figsize)\n",
    "#     nx.draw(\n",
    "#         g, \n",
    "#         pos=pos,\n",
    "#         node_size=10,\n",
    "#         width=0.5,\n",
    "#     )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def subtree_sizes(tree, root):\n",
    "    tree = nx.bfs_tree(g, source=root)\n",
    "    s = [len(nx.bfs_tree(tree, i).nodes) for i in tree.neighbors(root)]\n",
    "    total = sum(s)\n",
    "    return np.array(s)\n",
    "\n",
    "\n",
    "def fan(nodes, origin=[0,0], radius=1, phaseCenter=0, phaseRange=np.pi, ratio=[1,1]):\n",
    "    pos = {}\n",
    "    phases = {}\n",
    "    ranges = {}\n",
    "    n = len(nodes)\n",
    "    cos, sin = np.cos, np.sin\n",
    "    \n",
    "    ratioTotal = sum(ratio)\n",
    "    ratio = [r/ratioTotal for r in ratio]\n",
    "    \n",
    "    \n",
    "    nr = sorted(zip(nodes, ratio), key=lambda x:x[1])\n",
    "    nr2 = []\n",
    "    for i in range(len(nr)-1, -1, -1):\n",
    "        if i%2 == 0:\n",
    "            nr2.append(nr[i])\n",
    "        else:\n",
    "            nr2.insert(0, nr[i])\n",
    "    nodes, ratio = zip(*nr2)\n",
    "    \n",
    "    \n",
    "    ratioCumSum = [sum(ratio[:i]) for i in range(len(ratio)+1)]\n",
    "    for i in range(n):\n",
    "        angle_offset = (ratioCumSum[i]+ratioCumSum[i+1])/2 * phaseRange\n",
    "        angle_i = phaseCenter - phaseRange/2 + angle_offset\n",
    "        pos[nodes[i]] = [radius*cos(angle_i), radius*sin(angle_i)]\n",
    "        phases[nodes[i]] = angle_i\n",
    "        ranges[nodes[i]] = ratio[i] * phaseRange * 0.95\n",
    "    return pos, phases, ranges\n",
    "\n",
    "\n",
    "def radial_layout(g, root=None):\n",
    "    g0 = g\n",
    "    g = nx.bfs_tree(g, source=root)\n",
    "    origin = [0,0]\n",
    "    pos = {}\n",
    "    phases = {}\n",
    "    ranges = {}\n",
    "    if root is None:\n",
    "        root = next(iter(g.nodes))\n",
    "    pos[root] = origin\n",
    "    phases[root] = 0\n",
    "    ranges[root] = np.pi*2\n",
    "#     neighbors = list(g.neighbors(root))\n",
    "    radius = 0\n",
    "    roots = [root, ]\n",
    "    while len(pos) < len(g.nodes):\n",
    "        radius += 1\n",
    "        newRoots = []\n",
    "        for root in roots:\n",
    "            neighbors = [n for n in g.neighbors(root) if n not in pos]\n",
    "            subTreeSizes = [len(nx.bfs_tree(g, i).nodes) for i in neighbors]\n",
    "#             neighborSizes = [len(list(g0.neighbors(i))) for i in neighbors]\n",
    "            newRoots += neighbors\n",
    "            if len(neighbors) > 0:\n",
    "                newPos, newPhases, newRanges = fan(\n",
    "                    neighbors, \n",
    "                    origin, \n",
    "                    radius, \n",
    "                    phaseCenter=phases[root], \n",
    "                    phaseRange=ranges[root], \n",
    "                    ratio=subTreeSizes,\n",
    "                )\n",
    "                pos.update(newPos)\n",
    "                phases.update(newPhases)\n",
    "                ranges.update(newRanges)\n",
    "        roots = newRoots\n",
    "    return pos\n",
    "\n",
    "def normalize(node):\n",
    "    for prop in node:\n",
    "        \n",
    "            \n",
    "        if prop == 'pos':\n",
    "            pos = node[prop].replace('\"', '')\n",
    "            pos = pos.split(',')\n",
    "            pos = [float(pos[0]), float(pos[1])]\n",
    "            node[prop] = pos\n",
    "        else:\n",
    "            if type(node[prop]) == str:\n",
    "                node[prop] = node[prop].replace('\"', '')\n",
    "                \n",
    "            try:\n",
    "                node[prop] = int(node[prop])\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    node[prop] = float(node[prop])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                print(node, prop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### math genealogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = './data/txt/math-genealogy/data_names_shortened.txt'\n",
    "\n",
    "# label_to_id = {'K. Müller':66,'A. E. R. Kneschke':22,'B. Karstens':70,'K. E. Stork':35,'W. Fricke':9,'R. C. Straubel':8,'K. Ludwig':49,'W. Lauf':84,'R. Buchweitz':81,'A. K. Holzwarth':24,'O. Mayer':65,'W. von Heygendorff':2,'D. Schuldt':67,'L. Kämmerer':68,'J. Meyer':11,'H. Kessler':12,'G. H. Wannier':30,'V. Hartmann':69,'S. M. geb. Zacharias':56,'A. Hagenbach':3,'L. Neumann':16,'M. Mitchell':83,'M. D. Thomure':91,'E. Oettinger':18,'O. Volk':14,'W. Schorcht':10,'J. Ostwald':0,'M. T. geb. Deutschmann':58,'W. Landecker':89,'H. Tietz':33,'G. Schmieder':82,'K. Heun':6,'M. Krafft':17,'P. Peter':61,'A. Tafelmacher':7,'E. C. G. Stueckelberg':26,'M. Fruth':54,'K. Ebbinghaus':4,'K. J. Thomae':1,'H. Schreiter':51,'G. F. L. Frege':5,'G. Wiarda':19,'M. Cenek':92,'W. Müller':53,'F. W. M. Müller':23,'W. Merten':20,'E. Pippig':71,'P. Katilius':15,'H. Bückner':34,'K. Potthoff':78,'C. Schoen':64,'K. Mätzel':50,'D. Hudak':55,'M. Schoch':52,'H. K. O. Liebmann':13,'K. Neumann':57,'R. Hopsch':60,'G. Stiege':80,'D. R. Hofstadter':32,'D. Tzscharschuch':59,'P. Ghosh':93,'A. Thedy':21,'H. Jäckel':47,'R. Juengling':90,'V. Padervinskas':31,'A. Wolf':25,'E. C. J. Schering':5}\n",
    "# label_to_id['G. F. L. Frege'] = 999\n",
    "# id_to_label = {66:'K. Müller',22:'A. E. R. Kneschke',70:'B. Karstens',35:'K. E. Stork',9:'W. Fricke',8:'R. C. Straubel',49:'K. Ludwig',84:'W. Lauf',81:'R. Buchweitz',24:'A. K. Holzwarth',65:'O. Mayer',2:'W. von Heygendorff',67:'D. Schuldt',68:'L. Kämmerer',11:'J. Meyer',12:'H. Kessler',30:'G. H. Wannier',69:'V. Hartmann',56:'S. M. geb. Zacharias',3:'A. Hagenbach',16:'L. Neumann',83:'M. Mitchell',91:'M. D. Thomure',18:'E. Oettinger',14:'O. Volk',10:'W. Schorcht',0:'J. Ostwald',58:'M. T. geb. Deutschmann',89:'W. Landecker',33:'H. Tietz',82:'G. Schmieder',6:'K. Heun',17:'M. Krafft',61:'P. Peter',7:'A. Tafelmacher',26:'E. C. G. Stueckelberg',54:'M. Fruth',4:'K. Ebbinghaus',1:'K. J. Thomae',51:'H. Schreiter',5:'G. F. L. Frege',19:'G. Wiarda',92:'M. Cenek',53:'W. Müller',23:'F. W. M. Müller',20:'W. Merten',71:'E. Pippig',15:'P. Katilius',34:'H. Bückner',78:'K. Potthoff',64:'C. Schoen',50:'K. Mätzel',55:'D. Hudak',52:'M. Schoch',13:'H. K. O. Liebmann',57:'K. Neumann',60:'R. Hopsch',80:'G. Stiege',32:'D. R. Hofstadter',59:'D. Tzscharschuch',93:'P. Ghosh',21:'A. Thedy',47:'H. Jäckel',90:'R. Juengling',31:'V. Padervinskas',25:'A. Wolf',5:'E. C. J. Schering'}\n",
    "# id_to_label = {v:k for k,v in label_to_id.items()}\n",
    "\n",
    "my_edges = [['J. Ostwald', 'K. J. Thomae'], ['J. Ostwald', 'W. von Heygendorff'], ['J. Ostwald', 'A. Hagenbach'], ['J. Ostwald', 'K. Ebbinghaus'], ['K. J. Thomae', 'E. C. J. Schering'], ['E. C. J. Schering', 'G. F. L. Frege'], ['E. C. J. Schering', 'K. Heun'], ['E. C. J. Schering', 'A. Tafelmacher'], ['K. J. Thomae', 'R. C. Straubel'], ['R. C. Straubel', 'W. Fricke'], ['R. C. Straubel', 'W. Schorcht'], ['R. C. Straubel', 'J. Meyer'], ['R. C. Straubel', 'H. Kessler'], ['K. J. Thomae', 'H. K. O. Liebmann'], ['H. K. O. Liebmann', 'O. Volk'], ['H. K. O. Liebmann', 'P. Katilius'], ['K. J. Thomae', 'L. Neumann'], ['L. Neumann', 'M. Krafft'], ['L. Neumann', 'E. Oettinger'], ['L. Neumann', 'G. Wiarda'], ['L. Neumann', 'W. Merten'], ['R. C. Straubel', 'A. Thedy'], ['G. Wiarda', 'A. E. R. Kneschke'], ['H. K. O. Liebmann', 'F. W. M. Müller'], ['F. W. M. Müller', 'A. K. Holzwarth'], ['F. W. M. Müller', 'A. Wolf'], ['A. Hagenbach', 'E. C. G. Stueckelberg'], ['E. C. G. Stueckelberg', 'G. H. Wannier'], ['P. Katilius', 'V. Padervinskas'], ['G. H. Wannier', 'D. R. Hofstadter'], ['M. Krafft', 'H. Tietz'], ['M. Krafft', 'H. Bückner'], ['M. Krafft', 'K. E. Stork'], ['A. E. R. Kneschke', 'H. Jäckel'], ['H. Jäckel', 'K. Ludwig'], ['H. Jäckel', 'K. Mätzel'], ['H. Jäckel', 'H. Schreiter'], ['A. E. R. Kneschke', 'M. Schoch'], ['A. E. R. Kneschke', 'W. Müller'], ['K. Ludwig', 'M. Fruth'], ['K. Ludwig', 'D. Hudak'], ['K. Ludwig', 'S. M. geb. Zacharias'], ['K. Ludwig', 'K. Neumann'], ['K. Ludwig', 'M. T. geb. Deutschmann'], ['W. Müller', 'D. Tzscharschuch'], ['W. Müller', 'R. Hopsch'], ['W. Müller', 'P. Peter'], ['K. Neumann', 'C. Schoen'], ['K. Neumann', 'O. Mayer'], ['M. Schoch', 'K. Müller'], ['K. Müller', 'D. Schuldt'], ['K. Neumann', 'L. Kämmerer'], ['H. Schreiter', 'V. Hartmann'], ['H. Schreiter', 'B. Karstens'], ['H. Schreiter', 'E. Pippig'], ['H. Tietz', 'K. Potthoff'], ['H. Tietz', 'R. Buchweitz'], ['H. Tietz', 'G. Schmieder'], ['H. Tietz', 'G. Stiege'], ['D. R. Hofstadter', 'M. Mitchell'], ['G. Schmieder', 'W. Lauf'], ['M. Mitchell', 'W. Landecker'], ['M. Mitchell', 'R. Juengling'], ['M. Mitchell', 'M. D. Thomure'], ['M. Mitchell', 'M. Cenek'], ['M. Mitchell', 'P. Ghosh']]\n",
    "# edge_distance = {0:50,1:50,2:50,3:50,4:50,5:50,6:50,7:50,8:50,9:50,10:50,11:50,12:50,13:50,14:50,15:50,16:50,17:50,18:50,19:50,20:50,21:50,22:50,23:50,24:50,25:50,26:50,27:50,28:50,29:50,30:50,31:50,32:50,33:50,34:50,35:50,36:50,37:50,38:50,39:50,40:50,41:50,42:50,43:50,44:50,45:50,46:50,47:50,48:50,49:50,50:50,51:50,52:50,53:50,54:50,55:50,56:50,57:50,58:50,59:50,60:50,61:50,62:50,63:50,64:50,65:50,66:50}\n",
    "\n",
    "\n",
    "edges = sum(my_edges, [])\n",
    "labels = OrderedDict()\n",
    "labels.update(zip(edges,edges))\n",
    "\n",
    "label_to_id = {l:i for i,l in enumerate(labels)}\n",
    "id_to_label = {v:k for k,v in label_to_id.items()}\n",
    "\n",
    "\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(label_to_id.values())\n",
    "g.add_edges_from([[label_to_id[e0], label_to_id[e1]] for e0,e1 in my_edges])\n",
    "\n",
    "for i,n in enumerate(g.nodes):\n",
    "    g.nodes[n]['level'] = 1\n",
    "    g.nodes[n]['index'] = i\n",
    "    g.nodes[n]['id'] = n\n",
    "    g.nodes[n]['label'] = id_to_label[n]\n",
    "    \n",
    "for e in g.edges:\n",
    "    g.edges[e]['level'] = 1\n",
    "    g.edges[e]['weight'] = 50\n",
    "\n",
    "i2k = sorted(list(g.nodes))\n",
    "k2i = {k:i for i,k in enumerate(i2k)}\n",
    "\n",
    "\n",
    "print('all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight='weight')\n",
    "d = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = k2i[dk[0]]\n",
    "    target_dist = dk[1]\n",
    "    d[source,:] = [target_dist[i2k[i]] for i in range(len(g.nodes))]\n",
    "    \n",
    "    \n",
    "# print('k-hop all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight=1)\n",
    "hops = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = k2i[dk[0]]\n",
    "    target_dist = dk[1]\n",
    "    hops[source,:] = [target_dist[i2k[i]] for i in range(len(g.nodes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faryad's Google Topics - 500 / 5,000 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./data/txt/topics_faryad_5000/Graph_1600.txt', 7)\n",
      "./data/txt/topics_faryad_5000/Graph_1200.txt 6\n",
      "./data/txt/topics_faryad_5000/Graph_800.txt 5\n",
      "./data/txt/topics_faryad_5000/Graph_500.txt 4\n",
      "./data/txt/topics_faryad_5000/Graph_200.txt 3\n",
      "./data/txt/topics_faryad_5000/Graph_100.txt 2\n",
      "./data/txt/topics_faryad_5000/Graph_50.txt 1\n",
      "all_pairs_shortest_path...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af226c3a6d94c4e9db470aa29db4091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6775028fe88a43feaff13e821ee976ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def edges2graph(lines, i2k=None, label2i=None):\n",
    "    pattern = re.compile('\"(.+)\" -- \"(.+)\"')\n",
    "    nodes = set()\n",
    "    edges = set()\n",
    "    for line in lines:\n",
    "        if len(line.strip()) > 0:\n",
    "            edge = re.findall(pattern, line)[0]\n",
    "            source, target = edge\n",
    "            nodes.update([source, target])\n",
    "            edges.add( (source, target) )\n",
    "    \n",
    "    if label2i is None:\n",
    "        label2i = {k:i for i,k in enumerate(nodes)}\n",
    "        i2k = list(range(len(nodes)))\n",
    "    g = nx.Graph()\n",
    "    \n",
    "    nodes = [dict(id=label2i[k], label=k) for i,k in enumerate(nodes)]\n",
    "    ids = [n['id'] for n in nodes]\n",
    "    g.add_nodes_from( zip(ids, nodes) )\n",
    "    \n",
    "    edges = [(i2k[label2i[e[0]]],i2k[label2i[e[1]]]) for e in edges]\n",
    "    g.add_edges_from(edges)\n",
    "    return g, i2k, label2i\n",
    "\n",
    "\n",
    "# fns = natsorted(glob('./data/txt/topics_faryad_500/*.txt'))\n",
    "fns = natsorted(glob('./data/txt/topics_faryad_5000/*.txt'))[:7]\n",
    "fn_level_pairs = list(zip(fns, range(1, len(fns)+1, 1)))\n",
    "max_level = len(fns)\n",
    "\n",
    "print(fn_level_pairs[-1])\n",
    "with open(fns[-1]) as f:\n",
    "    g, i2k, label2i = edges2graph(f.readlines())\n",
    "    level = max_level\n",
    "    for n in g.nodes:\n",
    "        g.nodes[n]['level'] = level\n",
    "    for e in g.edges:\n",
    "        g.edges[e]['level'] = level\n",
    "        g.edges[e]['weight'] = (max_level - level + 1)*50\n",
    "        \n",
    "for fn, level in list(fn_level_pairs)[:-1][::-1]:\n",
    "    print(fn, level)\n",
    "    with open(fn) as f:\n",
    "        subgraph,_,_ = edges2graph(f.readlines(), i2k, label2i)\n",
    "        for n in subgraph.nodes:\n",
    "            g.nodes[n]['level'] = level\n",
    "            \n",
    "        for e in subgraph.edges:\n",
    "            g.edges[e]['level'] = level\n",
    "            g.edges[e]['weight'] = (max_level - level + 1)*50\n",
    "#             print(e, g.edges[e]['weight'])\n",
    "\n",
    "print('all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight='weight')\n",
    "d = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = dk[0]\n",
    "    target_dist = dk[1]\n",
    "    d[source,:] = [target_dist[i] for i in range(len(g.nodes))]\n",
    "    \n",
    "    \n",
    "# print('k-hop all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight=1)\n",
    "hops = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    source = dk[0]\n",
    "    target_dist = dk[1]\n",
    "    hops[source,:] = [target_dist[i] for i in range(len(g.nodes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ryn's lastfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ryn's lastfm\n",
    "\n",
    "print('loading graph...')\n",
    "\n",
    "fns = natsorted(glob('./data/dot/lastfm-ryn/*.dot'))\n",
    "fn_level_pairs = zip(fns, range(1, len(fns)+1, 1))\n",
    "\n",
    "# # ## load deepest level\n",
    "fn = fns[-1]\n",
    "g = nx.Graph(read_dot(fn))## multi-graph to graph\n",
    "\n",
    "max_level = len(fns)\n",
    "\n",
    "level = max_level\n",
    "for k in g.nodes:\n",
    "    g.nodes[k]['level'] = level\n",
    "    normalize(g.nodes[k])\n",
    "for e in g.edges:\n",
    "    g.edges[e]['weight'] = (max_level - level + 1)*50\n",
    "\n",
    "#     normalize(g.edges[e])\n",
    "    \n",
    "i2k = sorted(list(g.nodes), key=lambda x:int(x))\n",
    "k2i = {k:i for i,k in enumerate(i2k)}\n",
    "\n",
    "# # # ## modify node and edge attributes\n",
    "for i, fn in enumerate(fns[:-1][::-1], 1):\n",
    "    level = max_level - i\n",
    "    print(fn, level)\n",
    "    \n",
    "    gi = nx.Graph(read_dot(fn))## multi-graph to graph\n",
    "    for k in gi.nodes:\n",
    "        g.nodes[k]['level'] = level\n",
    "        normalize(g.nodes[k])\n",
    "    for e in gi.edges:\n",
    "        g.edges[e]['weight'] = (max_level - level + 1)*50\n",
    "        \n",
    "fn = fns[-1]\n",
    "\n",
    "\n",
    "adj = nx.adjacency_matrix(g).toarray().astype(np.float32)\n",
    "\n",
    "print('all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight='weight')\n",
    "d = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    k = dk[0]\n",
    "    d[k2i[k],:] = [dk[1][k] for k in i2k]\n",
    "    \n",
    "print('k-hop all_pairs_shortest_path...')\n",
    "apsp = nx.all_pairs_dijkstra_path_length(g, weight=1)\n",
    "hops = np.zeros([len(g.nodes),len(g.nodes)])\n",
    "for dk in tqdm(apsp):\n",
    "    k = dk[0]\n",
    "    hops[k2i[k],:] = [dk[1][k] for k in i2k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## real data\n",
    "# fn = './data/dot/topics-iqbal/Topics_Layer_1.dot'\n",
    "# # fn = './data/dot/lastfm-ryn/lastfm_155nodes.dot'\n",
    "# nodes = []\n",
    "# edges = []\n",
    "# with open(fn) as f:\n",
    "#     lines = f.readlines()[:-1]\n",
    "#     lines[0] = lines[0].split('{')[1].strip()\n",
    "#     for line in lines:\n",
    "#         if isNode(line):\n",
    "#             nodes.append(processNode(line))\n",
    "#         else:\n",
    "#             edges.append(processEdge(line))\n",
    "# n = len(nodes)\n",
    "# nodes = sorted(nodes, key=lambda x:x['id'])\n",
    "# i2k = [n['id'] for n in nodes]\n",
    "\n",
    "# g = nx.Graph()\n",
    "# g.add_nodes_from([n['id'] for n in nodes])\n",
    "# g.add_edges_from([(e['source'], e['target']) for e in edges])\n",
    "\n",
    "# print(len(nodes), len(edges), nx.is_tree(g))\n",
    "\n",
    "# adj = nx.adjacency_matrix(g)\n",
    "# adj = adj.toarray().astype(np.float)\n",
    "# # d = adj + (1-adj)*1000\n",
    "# # d *= (1-np.eye(len(nodes)))\n",
    "\n",
    "\n",
    "# ## all_pairs_shortest_path\n",
    "# apsp = nx.all_pairs_shortest_path_length(g)\n",
    "# d = np.zeros([len(nodes),len(nodes)])\n",
    "# for i,di in enumerate(tqdm(sorted(apsp))):\n",
    "#     nodeId = di[0]\n",
    "#     lengths = [di[1][k] for k in i2k]\n",
    "#     d[i,:] = lengths\n",
    "# #     print(nodeId)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test graph\n",
    "# g = nx.balanced_tree(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# pos0 = nx.layout.planar_layout(g, scale=40)\n",
    "# pos0 = graphviz_layout(g, prog=\"dot\", root=list(g.nodes)[0])\n",
    "# pos0 = graphviz_layout(g, prog='twopi')\n",
    "pos0 = graphviz_layout(g, prog='sfdp')\n",
    "pos = pos0.copy()\n",
    "dt = time() - t0\n",
    "print(f'{dt} sec')\n",
    "\n",
    "# from scipy.spatial.distance import jensenshannon\n",
    "# metric = []\n",
    "# for i in range(len(nodes)):\n",
    "#     s = subtree_sizes(g, i2k[i])\n",
    "#     uniform = np.ones(len(s)) / len(s)\n",
    "#     js = jensenshannon(s, uniform) \n",
    "#     metric.append(js)\n",
    "\n",
    "\n",
    "# metric = d.max(axis=1)\n",
    "# iBest = np.argmin(metric)\n",
    "# # iBest = np.argmax(metric)\n",
    "# pos = radial_layout(g, list(g.nodes)[iBest])\n",
    "\n",
    "\n",
    "# draw(g, pos, s=10, lw=1, labels=False, figsize=[64,64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(g, pos, s=10, lw=1, labels=False, figsize=[12,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw(g, pos, s=10, lw=1, labels=True, figsize=[12,12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crossing removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCrossed(e0, e1, pos=None):\n",
    "    p0,p1 = e0\n",
    "    q0,q1 = e1\n",
    "    \n",
    "    if p0 == q0 or p0 == q1 or p1==q0 or p1==q1: ##if two edges shares a node\n",
    "        return False\n",
    "    else:\n",
    "        p0 = pos[p0]\n",
    "        p1 = pos[p1]\n",
    "        q0 = pos[q0]\n",
    "        q1 = pos[q1]\n",
    "        e0 = (pos[e0[0]],pos[e0[1]])\n",
    "        e1 = (pos[e1[0]],pos[e1[1]])\n",
    "        \n",
    "        s00 = signOf(q0, e0)\n",
    "        s10 = signOf(q1, e0)\n",
    "        s01 = signOf(p0, e1)\n",
    "        s11 = signOf(p1, e1)\n",
    "        return s00*s10 <= 0 and s01*s11 <= 0 \n",
    "\n",
    "    \n",
    "def signOf(p, e):\n",
    "    '''sign of point p with repect to the line of edge e'''\n",
    "    px, py = p\n",
    "    ax, ay = e[0]\n",
    "    bx, by = e[1]\n",
    "    \n",
    "    a = ay - by\n",
    "    b = bx - ax\n",
    "    c = ay * (ax - bx) - ax * (ay - by)\n",
    "    \n",
    "    z = px*a + py*b + c\n",
    "    return np.sign(z)\n",
    "\n",
    "\n",
    "def subtreeSize(tree, node):\n",
    "    subtree = nx.bfs_tree(tree, node)\n",
    "    return len(subtree.nodes), subtree\n",
    "\n",
    "\n",
    "def shrink(subtree=None, origin=0, by=0.5, pos=None):\n",
    "    scaleFactor = by\n",
    "    ox, oy = pos[origin]\n",
    "    for k in subtree.nodes:\n",
    "        x,y = pos[k]\n",
    "        x = ox + scaleFactor * (x-ox)\n",
    "        y = oy + scaleFactor * (y-oy)\n",
    "        pos[k] = (x,y)\n",
    "\n",
    "        \n",
    "## find a good root\n",
    "id_pos = pos.items()\n",
    "\n",
    "ids = np.array([i[0] for i in id_pos])\n",
    "x = np.array([i[1] for i in id_pos])\n",
    "\n",
    "centroid = np.mean(x, 0)\n",
    "dist_to_centroid = np.linalg.norm(x - centroid, 2, 1)\n",
    "root = ids[np.argmin(dist_to_centroid)]\n",
    "print('root:', g.nodes[root])\n",
    "\n",
    "tree = nx.bfs_tree(g, source=root)\n",
    "scaleFactor = 0.7\n",
    "hasCrossing = True\n",
    "while hasCrossing:\n",
    "    hasCrossing = False\n",
    "    for e0 in g.edges:\n",
    "        for e1 in g.edges:\n",
    "            if isCrossed(e0, e1, pos):\n",
    "                hasCrossing = True\n",
    "    #             print(e0, e1)\n",
    "                sts0, subtree0 = subtreeSize(tree, e0[1])\n",
    "                sts1, subtree1 = subtreeSize(tree, e1[1])\n",
    "                if sts0 < sts1:\n",
    "                    shrink(subtree=subtree0, by=scaleFactor, origin=e0[0], pos=pos)\n",
    "                else:\n",
    "                    shrink(subtree=subtree1, by=scaleFactor, origin=e1[0], pos=pos)\n",
    "                clear_output(wait=True)\n",
    "                draw(g, pos, labels=False, s=10, lw=1, figsize=[5,5])\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xy = np.array( [ pos[i2k[i]]for i in range(len(nodes)) ] )\n",
    "# theta = (xy[:,0] - xy[:,0].min()) / (xy[:,0].max() - xy[:,0].min()) * np.pi*1\n",
    "# r = (xy[:,1] - xy[:,1].min())\n",
    "# # r = -(xy[:,1] - xy[:,1].max())\n",
    "\n",
    "# xy2 = np.c_[r*np.cos(theta), r*np.sin(theta)]\n",
    "# pos2 = {i2k[i]:xy2[i] for i in range(len(nodes))}\n",
    "# draw(g, pos2)\n",
    "\n",
    "# # pos = pos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap import UMAP\n",
    "\n",
    "# n_neighbors = 15\n",
    "\n",
    "# umap = UMAP(\n",
    "#     n_components=2,\n",
    "#     n_neighbors=n_neighbors, \n",
    "#     min_dist=0.3,\n",
    "#     metric='precomputed',\n",
    "# #     n_epochs=500,\n",
    "# #     negative_sample_rate=150,\n",
    "# #     learning_rate=0.0001,\n",
    "# #     init=np.array(list(pos.values()))\n",
    "# )\n",
    "# xy = umap.fit_transform(d)\n",
    "# pos2 = {i2k[i]:xy[i,:2] for i in range(len(nodes))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Ordering of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##max degree node\n",
    "degree = list(g.degree)\n",
    "degree = list(zip(range(len(degree)), degree))\n",
    "max_degree_node = max(degree, key=lambda x:x[1][1])\n",
    "start = max_degree_node[1][0]\n",
    "\n",
    "## random node, bfs\n",
    "# start = next(iter(g.nodes.keys()))\n",
    "node_order = list(nx.bfs_tree(g, start))\n",
    "\n",
    "##dfs\n",
    "# node_order = list(nx.dfs_preorder_nodes(g, start))\n",
    "\n",
    "## no re-ordering\n",
    "# node_order = list(g.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##graph to list\n",
    "nodes = {k: g.nodes[k] for k in g.nodes}\n",
    "edges = [[e[0], e[1], g.edges[e]] for e in g.edges]\n",
    "nodes = [{\n",
    "    'id': node_order[i],\n",
    "    'index': i,\n",
    "    **nodes[node_order[i]]\n",
    "} for i in range(len(nodes))]\n",
    "edges = [{\n",
    "    'source': e[0],\n",
    "    'target': e[1],\n",
    "    **e[2]\n",
    "} for e in edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1601"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e200aa8a9af4d01bf887d2cf879ee4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1601.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./data/json/topics_faryad_5000/Graph_50.json\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# ##store the position & perplexity\n",
    "for i,node in enumerate(nodes):\n",
    "#     node['x'] = pos[node_order[i]][0]\n",
    "#     node['y'] = pos[node_order[i]][1]\n",
    "    node['neighbors'] = list(nx.neighbors(g, node['id']))\n",
    "#     node['x'] = node['pos'][0]\n",
    "#     node['y'] = node['pos'][1]\n",
    "    node['perplexity'] = len(list(nx.neighbors(g, node_order[i])))\n",
    "\n",
    "\n",
    "virtual_edges = []\n",
    "for i in tqdm(range(len(nodes))):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        if d[i,j] == 0:\n",
    "            print(f'[warning] d[{i},{j}] = 0')\n",
    "#         elif hops[i,j] > 12:\n",
    "#             continue\n",
    "        else:\n",
    "            e = {\n",
    "                'source': i2k[i],\n",
    "                'target': i2k[j],\n",
    "                'weight': d[i,j],\n",
    "                'hops': hops[i,j]\n",
    "            }\n",
    "            virtual_edges.append(e)\n",
    "        \n",
    "fn_out = fn.replace('dot', 'json').replace('txt', 'json')\n",
    "print(fn_out)\n",
    "\n",
    "if not Path(fn_out).parent.exists():\n",
    "    os.makedirs(Path(fn_out).parent)\n",
    "with open(fn_out, 'w') as f:\n",
    "    json.dump(dict(\n",
    "        edges = edges, \n",
    "        virtual_edges = virtual_edges, \n",
    "        nodes=nodes\n",
    "    ), f, indent=2)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(g.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nodes:\n",
    "    n['id'] = n['index']\n",
    "    del n['x']\n",
    "    del n['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
